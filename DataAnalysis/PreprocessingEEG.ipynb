{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from mne import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from autoreject import AutoReject\n",
    "import pickle\n",
    "import os\n",
    "from pybv import write_brainvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from pilot_2001\\2001_awake_ec.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m raw \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mread_raw_brainvision(file_path)\n\u001b[0;32m     16\u001b[0m \u001b[39m#Plot EEG data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m raw\u001b[39m.\u001b[39;49mplot(duration\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, n_channels\u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m, scalings \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m, block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     18\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m plt\u001b[39m.\u001b[39mwaitforbuttonpress(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\base.py:1530\u001b[0m, in \u001b[0;36mBaseRaw.plot\u001b[1;34m(self, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[39m@copy_function_doc_to_method_doc\u001b[39m(plot_raw)\n\u001b[0;32m   1520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39mself\u001b[39m, events\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, duration\u001b[39m=\u001b[39m\u001b[39m10.0\u001b[39m, start\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, n_channels\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m   1521\u001b[0m          bgcolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bad_color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlightgray\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m          precompute\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, use_opengl\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, theme\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1529\u001b[0m          overview_mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1530\u001b[0m     \u001b[39mreturn\u001b[39;00m plot_raw(\u001b[39mself\u001b[39;49m, events, duration, start, n_channels, bgcolor,\n\u001b[0;32m   1531\u001b[0m                     color, bad_color, event_color, scalings, remove_dc,\n\u001b[0;32m   1532\u001b[0m                     order, show_options, title, show, block, highpass,\n\u001b[0;32m   1533\u001b[0m                     lowpass, filtorder, clipping, show_first_samp,\n\u001b[0;32m   1534\u001b[0m                     proj, group_by, butterfly, decim, noise_cov\u001b[39m=\u001b[39;49mnoise_cov,\n\u001b[0;32m   1535\u001b[0m                     event_id\u001b[39m=\u001b[39;49mevent_id, show_scrollbars\u001b[39m=\u001b[39;49mshow_scrollbars,\n\u001b[0;32m   1536\u001b[0m                     show_scalebars\u001b[39m=\u001b[39;49mshow_scalebars, time_format\u001b[39m=\u001b[39;49mtime_format,\n\u001b[0;32m   1537\u001b[0m                     precompute\u001b[39m=\u001b[39;49mprecompute, use_opengl\u001b[39m=\u001b[39;49muse_opengl,\n\u001b[0;32m   1538\u001b[0m                     theme\u001b[39m=\u001b[39;49mtheme, overview_mode\u001b[39m=\u001b[39;49moverview_mode,\n\u001b[0;32m   1539\u001b[0m                     verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32m<decorator-gen-157>:12\u001b[0m, in \u001b[0;36mplot_raw\u001b[1;34m(raw, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\viz\\raw.py:215\u001b[0m, in \u001b[0;36mplot_raw\u001b[1;34m(raw, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39m# handle defaults / check arg validity\u001b[39;00m\n\u001b[0;32m    214\u001b[0m color \u001b[39m=\u001b[39m _handle_default(\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m, color)\n\u001b[1;32m--> 215\u001b[0m scalings \u001b[39m=\u001b[39m _compute_scalings(scalings, raw, remove_dc\u001b[39m=\u001b[39;49mremove_dc,\n\u001b[0;32m    216\u001b[0m                              duration\u001b[39m=\u001b[39;49mduration)\n\u001b[0;32m    217\u001b[0m \u001b[39mif\u001b[39;00m scalings[\u001b[39m'\u001b[39m\u001b[39mwhitened\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    218\u001b[0m     scalings[\u001b[39m'\u001b[39m\u001b[39mwhitened\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\viz\\utils.py:1281\u001b[0m, in \u001b[0;36m_compute_scalings\u001b[1;34m(scalings, inst, remove_dc, duration)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     tmax \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(time_middle \u001b[39m+\u001b[39m n_secs \u001b[39m/\u001b[39m \u001b[39m2.\u001b[39m, \u001b[39mNone\u001b[39;00m, inst\u001b[39m.\u001b[39mtimes\u001b[39m.\u001b[39mmax())\n\u001b[0;32m   1279\u001b[0m     smin, smax \u001b[39m=\u001b[39m [\n\u001b[0;32m   1280\u001b[0m         \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(x \u001b[39m*\u001b[39m inst\u001b[39m.\u001b[39minfo[\u001b[39m'\u001b[39m\u001b[39msfreq\u001b[39m\u001b[39m'\u001b[39m])) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (tmin, tmax)]\n\u001b[1;32m-> 1281\u001b[0m     data \u001b[39m=\u001b[39m inst\u001b[39m.\u001b[39;49m_read_segment(smin, smax)\n\u001b[0;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inst, BaseEpochs):\n\u001b[0;32m   1283\u001b[0m     \u001b[39m# Load a random subset of epochs up to 100mb in size\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m     n_epochs \u001b[39m=\u001b[39m \u001b[39m1e8\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m (\u001b[39mlen\u001b[39m(inst\u001b[39m.\u001b[39mch_names) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(inst\u001b[39m.\u001b[39mtimes) \u001b[39m*\u001b[39m \u001b[39m8\u001b[39m)\n",
      "File \u001b[1;32m<decorator-gen-224>:12\u001b[0m, in \u001b[0;36m_read_segment\u001b[1;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\base.py:392\u001b[0m, in \u001b[0;36mBaseRaw._read_segment\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[39m# reindex back to original file\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     orig_idx \u001b[39m=\u001b[39m _convert_slice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_picks[fi][need_idx])\n\u001b[1;32m--> 392\u001b[0m     _ReadSegmentFileProtector(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[0;32m    393\u001b[0m         data[:, this_sl], orig_idx, fi,\n\u001b[0;32m    394\u001b[0m         \u001b[39mint\u001b[39;49m(start_file), \u001b[39mint\u001b[39;49m(stop_file), cals, mult)\n\u001b[0;32m    395\u001b[0m     offset \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_read\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\base.py:2145\u001b[0m, in \u001b[0;36m_ReadSegmentFileProtector._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m   2144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_segment_file\u001b[39m(\u001b[39mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[1;32m-> 2145\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__raw\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[0;32m   2146\u001b[0m         \u001b[39mself\u001b[39;49m, data, idx, fi, start, stop, cals, mult)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\brainvision\\brainvision.py:127\u001b[0m, in \u001b[0;36mRawBrainVision._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(fmt, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    126\u001b[0m     dtype \u001b[39m=\u001b[39m _fmt_dtype_dict[fmt]\n\u001b[1;32m--> 127\u001b[0m     _read_segments_file(\u001b[39mself\u001b[39;49m, data, idx, fi, start, stop, cals, mult,\n\u001b[0;32m    128\u001b[0m                         dtype\u001b[39m=\u001b[39;49mdtype, n_channels\u001b[39m=\u001b[39;49mn_data_ch)\n\u001b[0;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     offsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_extras[fi][\u001b[39m'\u001b[39m\u001b[39moffsets\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\utils.py:221\u001b[0m, in \u001b[0;36m_read_segments_file\u001b[1;34m(raw, data, idx, fi, start, stop, cals, mult, dtype, n_channels, offset, trigger_ch)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mfor\u001b[39;00m sample_start \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, data_left, block_size) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_channels:\n\u001b[0;32m    220\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(block_size, data_left \u001b[39m-\u001b[39m sample_start \u001b[39m*\u001b[39m n_channels)\n\u001b[1;32m--> 221\u001b[0m     block \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromfile(fid, dtype, count)\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m block\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m count:\n\u001b[0;32m    223\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mIncorrect number of samples (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m), \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    224\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mplease report this error to MNE-Python \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    225\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mdevelopers\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (block\u001b[39m.\u001b[39msize, count))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Make plots pop out in window\n",
    "%matplotlib qt\n",
    "\n",
    "#Change working directory to loop through files\n",
    "os.chdir('Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych')\n",
    "#Create a dictionary containing all files by participant, including cleaned files\n",
    "root_folder = 'Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych'\n",
    "\n",
    "for folder in os.listdir(root_folder):\n",
    "    for filename in os.listdir(folder):\n",
    "            if filename.endswith('.vhdr'):\n",
    "                # Create the file path by joining the directory path and the filename\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                # Load the vhdr file using mne.io.read_raw_brainvision() function\n",
    "                raw = io.read_raw_brainvision(file_path)\n",
    "                #Plot EEG data\n",
    "                raw.plot(duration=10, start=0, n_channels= 64, scalings = 'auto', block=False)\n",
    "                while True:\n",
    "                    if plt.waitforbuttonpress(0) == True:\n",
    "                        plt.close(\"all\")\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from Z:\\Data\\Anesthesia_Project\\Kongsberg_ED_Study\\psych\\SD5010\\SD5010_INDUCTION.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from Z:\\Data\\Anesthesia_Project\\Kongsberg_ED_Study\\psych\\SD5007\\SD5007_INDUCTION.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    }
   ],
   "source": [
    "####### Slice up induction to create SED_1 variables and remove the segment ###### \n",
    "\n",
    "###SD5010###\n",
    "IND = io.read_raw_brainvision('Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych\\\\SD5010\\\\SD5010_INDUCTION.vhdr')\n",
    "IND = IND.copy()\n",
    "SED_1 = IND.copy()\n",
    "IND = IND.crop(tmax=68)\n",
    "SED_1 = SED_1.crop(tmin=68)\n",
    "\n",
    "#Pickle the sliced variable as SD5010 \n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5010\\SD5010_SED_1_Sliced.pickle', 'wb') as f:\n",
    "    pickle.dump(SED_1, f)\n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5010\\SD5010_IND_Sliced.pickle', 'wb') as g:\n",
    "    pickle.dump(IND, g)\n",
    "\n",
    "###SD5007###\n",
    "IND = io.read_raw_brainvision('Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych\\\\SD5007\\\\SD5007_INDUCTION.vhdr')\n",
    "IND = IND.copy()\n",
    "SED_1 = IND.copy()\n",
    "IND = IND.crop(tmax=150)\n",
    "SED_1 = SED_1.crop(tmin=150, tmax=384)\n",
    "\n",
    "#Pickle the sliced variable as SD5010\n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5007\\SD5007_SED_1_Sliced.pickle', 'wb') as f:\n",
    "    pickle.dump(SED_1, f)\n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5007\\SD5007_IND_Sliced.pickle', 'wb') as g:\n",
    "    pickle.dump(IND, g)\n",
    "\n",
    "###SD5009###\n",
    "IND = io.read_raw_brainvision('Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych\\\\SD5009\\\\SD5009_INDUCTION.vhdr')\n",
    "IND = IND.copy()\n",
    "SED_1 = IND.copy()\n",
    "IND = IND.crop(tmax=309)\n",
    "SED_1 = SED_1.crop(tmin=150, tmax=384)\n",
    "\n",
    "#Pickle the sliced variable as SD5010\n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5009\\SD5009_SED_1_Sliced.pickle', 'wb') as f:\n",
    "    pickle.dump(SED_1, f)\n",
    "with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5009\\SD5009_IND_Sliced.pickle', 'wb') as g:\n",
    "    pickle.dump(IND, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All possible filenames to iterate through for each participant \n",
    "File_names = [\"EMERGENCE\", \"REST_EC\", \"REST_EO\", \"INDUCTION\", \"SED_1\", \"SED_2\", \"SED_3\", \"SED_4\"]\n",
    "#Which files to iterate through for each participant\n",
    "What2Slice = {\"Pilot_2001\": [1,0,3,5], \"SD5001\": [1,0,3], \"SD5002\": [0,1,3,4,5,6,7], \"SD5007\": [0,5,6,7], \"SD5008\": [7], \"SD5009\": [0,7], \"SD5010\": [0,5]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SliceEm():\n",
    "    #Create a dictionary containing all files by participant, including cleaned files\n",
    "    root_folder = 'Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych'\n",
    "\n",
    "    SliceBn = 0\n",
    "    for folder in os.listdir(root_folder):\n",
    "        for filename in os.listdir(folder):\n",
    "                if filename.endswith('.vhdr'):\n",
    "                    # Create the file path by joining the directory path and the filename\n",
    "                    file_path = os.path.join(folder, filename)\n",
    "                    # Load the vhdr file using mne.io.read_raw_brainvision() function\n",
    "                    print(filename)\n",
    "                    raw = io.read_raw_brainvision(file_path)\n",
    "                    # Visualize data and take notes on channels and segments\n",
    "                    SliceBn = input(\"Do you want to slice?\")\n",
    "                    while SliceBn == \"yes\":\n",
    "                        StartSl = input(\"Where should the slice start?\")\n",
    "                        StopSl = input(\"Where should the slice end?\")\n",
    "                        EEGData = io.read_raw_brainvision(file_path)\n",
    "                        EEGDataCopy = EEGData.copy()\n",
    "                        EEGDataCopy = EEGDataCopy.crop(tmin=StartSl, tmax=StopSl)\n",
    "                        #Pickle the sliced variable\n",
    "                        with open(r'{NuFilename}.pickle', 'wb') as f:\n",
    "                            pickle.dump(EEGDataCopy, f)\n",
    "                        with open(r'\\\\platon.uio.no\\med-imb-u1\\andrlm\\pc\\Dokumenter\\GitHub\\Ketamine-project\\DataAnalysis\\EEG_analysis\\SlicedAndPrepped\\SD5009\\SD5009_IND_Sliced.pickle', 'wb') as g:\n",
    "                            pickle.dump(EEGDataCopy, g)\n",
    "                        print(\"The file has been saved as a pickled file in platon and C: drive\")\n",
    "                        SliceBn = input(\"Do you want to slice more?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepross(folder):\n",
    "    #Create a dictionary containing all files by participant, including cleaned files\n",
    "    root_folder = 'Z:\\\\Data\\\\Anesthesia_Project\\\\Kongsberg_ED_Study\\\\psych'\n",
    "    folder_path = os.path.join(root_folder, folder)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.vhdr'):\n",
    "                # Create the file path by joining the directory path and the filename\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                # Load the vhdr file using mne.io.read_raw_brainvision() function\n",
    "                raw = io.read_raw_brainvision(file_path)\n",
    "                # Visualize data and take notes on channels and segments\n",
    "                inp = 1\n",
    "                while inp != 'Done':\n",
    "                    try:\n",
    "                        raw.plot(duration=10, start=0, n_channels= 64, scalings = 'auto', block=True)\n",
    "                        inp = input(\"If you have finished data visualization, write Done:\" )\n",
    "                        if user_input.lower() == \"Done\":\n",
    "                            break\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter a value or 'Done'.\")\n",
    "                #Interpolate bad channels\n",
    "                Bad_chans = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        user_input = input(\"Enter a channel you want to interpolate (or type 'done' to finish): \")\n",
    "                        if user_input.lower() == \"done\":\n",
    "                            break\n",
    "                        else:\n",
    "                            Bad_chans.append(int(user_input))\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter a value or 'done'.\")\n",
    "                #Interpolate bad channels based on \"Bad_chan\" variable\n",
    "                raw.info['bads'] = Bad_chans\n",
    "                raw.load_data()\n",
    "                raw_interp = raw.copy().interpolate_bads(reset_bads=False)\n",
    "                #pickle data file to load manually if needed\n",
    "                with open(filename + \"_interpolated\") as f:\n",
    "                    pickle.dump(raw_interp, f)\n",
    "                \n",
    "                ##### Remove data from bad segments #####\n",
    "                #Create events with a fixed 10 second interval\n",
    "                make_fixed_length_events = io.make_fixed_length_events\n",
    "                events = make_fixed_length_events(raw_interp, start=0, id=1, duration=10, overlap=0)\n",
    "                #Create epochs based on events\n",
    "                epochs = io.Epochs(raw_interp, events)\n",
    "                #Drop bad epochs\n",
    "                Bad_epochs = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        user_input = input(\"Enter a channel you want to interpolate as integer (or type 'done' to finish): \")\n",
    "                        if user_input.lower() == \"done\":\n",
    "                            break\n",
    "                        else:\n",
    "                            Bad_chans.append(int(user_input))\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter a value or 'done'.\")\n",
    "                #Drop bad epochs\n",
    "                epochs_clean = epochs.drop(Bad_epochs)\n",
    "                #pickle data file to load manually if needed\n",
    "                with open(filename + \"_interpolated\") as f:\n",
    "                    pickle.dump(raw_interp, f)\n",
    "               \n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datadic = {'pilot_2001': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition},\n",
    "            'SD5001': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition},\n",
    "            'SD5002': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition}, \n",
    "            'SD5007': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition},\n",
    "            'SD5008': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition},\n",
    "            'SD5009': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition},\n",
    "            'SD5010': {'raw_dat': raw, 'intp_chans': raw_interp, 'Epo_clean': epochs_clean, 'filt': filtered_dat, 'cond': condition}}\n",
    "\n",
    "    pickle.dump(datadic, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "142fce53b6f2b91b97dca80dfeb7f3677964d22b620fffd446cffe90630072c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
